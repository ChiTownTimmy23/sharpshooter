{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f68f1440ea004762",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T18:19:52.478911Z",
     "start_time": "2024-09-09T18:19:51.116294Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import polars as pl\n",
    "import httpx\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "from sqlalchemy import create_engine\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "\n",
    "# Import from the _models directory and madden.py file\n",
    "from sharpshooter.notebooks._models.madden import PlayerRating, RatingsResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a3effefe48bc4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T18:20:06.475716Z",
     "start_time": "2024-09-09T18:20:06.467530Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the number of rows to display\n",
    "pl.Config.set_tbl_cols(-1)  # None means no limit; you can also specify an integer.\n",
    "\n",
    "# Set the number of columns to display\n",
    "pl.Config.set_tbl_rows(-1)  # None means no limit; you can also specify an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30c151890a0b3a",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae794df34397b85e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T17:36:55.794413Z",
     "start_time": "2024-09-03T17:36:55.790403Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a Function that Gets the Headers of the dataframe and stores them in a list\n",
    "def get_headers(df):\n",
    "    headers_with_types = [(col, df[col].dtype) for col in df.columns]\n",
    "    # Sort by data type first, then alphabetically within each data type\n",
    "    sorted_headers = sorted(headers_with_types, key=lambda x: (str(x[1]), x[0]))\n",
    "    sorted_headers_list = [col for col, dtype in sorted_headers]\n",
    "    return sorted_headers, sorted_headers_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2e4ae7ed0c1f82",
   "metadata": {},
   "source": [
    "# Madden Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b95af5a1a1c6c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T17:36:57.797274Z",
     "start_time": "2024-09-03T17:36:57.794389Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_URL = \"https://ratings-api.ea.com/v2/entities\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9dd89ad08fa6e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T17:37:05.566825Z",
     "start_time": "2024-09-03T17:37:05.560705Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_madden_ratings(game_version: str, iteration: str) -> pl.DataFrame:\n",
    "    url = f\"{BASE_URL}/{game_version}-ratings?filter=iteration:{iteration}\"\n",
    "    all_ratings = []\n",
    "\n",
    "    with httpx.Client() as client:\n",
    "        response = client.get(url)\n",
    "        data = response.json()\n",
    "        ratings_response = RatingsResponse(**data)\n",
    "        all_ratings.extend(ratings_response.docs)\n",
    "\n",
    "        total_count = ratings_response.count\n",
    "        while len(all_ratings) < total_count:\n",
    "            next_url = f\"{url}&limit=100&offset={len(all_ratings)}\"\n",
    "            response = client.get(next_url)\n",
    "            data = response.json()\n",
    "            ratings_response = RatingsResponse(**data)\n",
    "            all_ratings.extend(ratings_response.docs)\n",
    "\n",
    "    # Convert the list of PlayerRating objects to a list of dictionaries\n",
    "    ratings_dicts = [rating.dict() for rating in all_ratings]\n",
    "\n",
    "    # Create a Polars DataFrame from the list of dictionaries\n",
    "    df = pl.DataFrame(ratings_dicts)\n",
    "\n",
    "    # Add a fullName column\n",
    "    df = df.with_columns(\n",
    "        (pl.col(\"firstName\") + \" \" + pl.col(\"lastName\")).alias(\"fullName\")\n",
    "    )\n",
    "\n",
    "    # Add a new madden_version column based on the game_version parameter\n",
    "    df = df.with_columns(pl.lit(game_version).alias(\"madden_version\"))\n",
    "\n",
    "    # Define the game version descriptions\n",
    "    game_version_descriptions = {\n",
    "        \"m21\": \"Madden 21\",\n",
    "        \"m22\": \"Madden 22\",\n",
    "        \"m23\": \"Madden 23\",\n",
    "        \"m24\": \"Madden 24\",\n",
    "    }\n",
    "\n",
    "    # Create a function to map game versions to descriptions\n",
    "    def map_game_version(version):\n",
    "        return game_version_descriptions.get(version, version)\n",
    "\n",
    "    # Add the new columns to the DataFrame\n",
    "    df = df.with_columns([\n",
    "        pl.lit(game_version).alias(\"madden_version\"),\n",
    "        pl.col(\"madden_version\").map_elements(map_game_version, return_dtype=pl.Utf8).alias(\"madden_description\")\n",
    "    ])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a622b624afd4b121",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T17:39:21.257822Z",
     "start_time": "2024-09-03T17:39:11.690038Z"
    }
   },
   "outputs": [],
   "source": [
    "madden_data = get_madden_ratings(\"m24\", \"launch-ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa448441",
   "metadata": {},
   "outputs": [],
   "source": [
    "madden_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876f9af03db7e790",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T17:39:26.590485Z",
     "start_time": "2024-09-03T17:39:26.581643Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def parse_date(date_str):\n",
    "    formats = [\"%m/%d/%Y\", \"%m/%d/%y\"]\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt).date()\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None  # Return None if no format matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59405161",
   "metadata": {},
   "outputs": [],
   "source": [
    "madden_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bcd3fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T18:20:20.573304Z",
     "start_time": "2024-09-09T18:20:20.556805Z"
    }
   },
   "outputs": [],
   "source": [
    "def store_to_postgres(df: pl.DataFrame, schema: str, table_name: str):\n",
    "    # Database connection details\n",
    "    db_username = \"\"\n",
    "    db_password = \"\"\n",
    "    db_host = \"localhost\"\n",
    "    db_port = \"5432\"\n",
    "    db_name = \"sportsdata\"\n",
    "\n",
    "    # Create SQLAlchemy engine\n",
    "    engine = create_engine(f\"postgresql://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}\")\n",
    "\n",
    "    # Convert Polars DataFrame to Pandas DataFrame\n",
    "    pandas_df = df.to_pandas()\n",
    "\n",
    "    # Store the dataframe to the database\n",
    "    pandas_df.to_sql(table_name, engine, schema=schema, if_exists=\"append\", index=True)\n",
    "\n",
    "    print(f\"Data successfully stored in {schema}.{table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b49c537",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T17:39:48.856777Z",
     "start_time": "2024-09-03T17:39:47.725157Z"
    }
   },
   "outputs": [],
   "source": [
    "store_to_postgres(madden_data, \"raw\", \"m24__player_ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e1ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    madden_data = get_madden_ratings(\"m24\", \"week-5\")\n",
    "    madden_data = madden_data.with_columns(\n",
    "    pl.col(\"plyrBirthdate\").map_elements(parse_date, return_dtype=pl.Date).alias(\"plyrBirthdate\")\n",
    ")\n",
    "\n",
    "# Handle any remaining null values\n",
    "madden_data = madden_data.with_columns(\n",
    "    pl.when(pl.col(\"plyrBirthdate\").is_null())\n",
    "    .then(pl.lit(None).cast(pl.Date))\n",
    "    .otherwise(pl.col(\"plyrBirthdate\"))\n",
    "    .alias(\"plyrBirthdate\")\n",
    ")\n",
    "store_to_postgres(madden_data, \"raw\", \"m24__player_ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad2395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_madden_data_for_weeks(start_week: int, end_week: int):\n",
    "    for week in range(start_week, end_week + 1):\n",
    "        week_str = f\"week-{week}\"\n",
    "        print(f\"Processing {week_str}...\")\n",
    "        madden_data = get_madden_ratings(\"m24\", week_str)\n",
    "        \n",
    "        # Handle date parsing\n",
    "        madden_data = madden_data.with_columns(\n",
    "            pl.col(\"plyrBirthdate\").map_elements(parse_date, return_dtype=pl.Date).alias(\"plyrBirthdate\")\n",
    "        )\n",
    "\n",
    "        # Handle any remaining null values\n",
    "        madden_data = madden_data.with_columns(\n",
    "            pl.when(pl.col(\"plyrBirthdate\").is_null())\n",
    "            .then(pl.lit(None).cast(pl.Date))\n",
    "            .otherwise(pl.col(\"plyrBirthdate\"))\n",
    "            .alias(\"plyrBirthdate\")\n",
    "        )\n",
    "        \n",
    "        # Store the data\n",
    "        table_name = f\"m24__player_ratings\"\n",
    "        store_to_postgres(madden_data, \"raw\", table_name)\n",
    "        print(f\"Stored data for {week_str}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    store_madden_data_for_weeks(6, 18)  # This will process weeks 5 through 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc02ca47e537799",
   "metadata": {},
   "source": [
    "# NFL Verse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12998f41391dd324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to read parquet data from the NFL Verse repo\n",
    "def get_nflverse_roster_data():\n",
    "    url = 'https://github.com/nflverse/nflverse-data/releases/download/rosters/roster_2023.parquet'\n",
    "    df = pl.read_parquet(url)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e15e241ee418a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:34:36.257989Z",
     "start_time": "2024-09-09T14:34:36.244995Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function to read parquet data from the NFL Verse repo\n",
    "def get_nflverse_player_data():\n",
    "    url = 'https://github.com/nflverse/nflverse-data/releases/download/players/players.parquet'\n",
    "    df = pl.read_parquet(url)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041d3108de1a246",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T18:20:32.780243Z",
     "start_time": "2024-09-09T18:20:32.774448Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function to read parquet data from the NFL Verse repo that accepts and argument as 'year'\n",
    "def get_nflverse_depth_charts_data(year: int):\n",
    "    url = f'https://github.com/nflverse/nflverse-data/releases/download/depth_charts/depth_charts_{year}.parquet'\n",
    "    df = pl.read_parquet(url)\n",
    "    return df   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dceeb8d20346a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to read parquet data from the NFL Verse repo that accepts and argument as 'year'\n",
    "def get_nflverse_weekly_rosters_data(year: int):\n",
    "    url = f'https://github.com/nflverse/nflverse-data/releases/download/weekly_rosters/roster_weekly_{year}.parquet'\n",
    "    df = pl.read_parquet(url)\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceefca7bc361a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to read parquet data from the NFL Verse repo that accepts and argument as 'year'\n",
    "def get_nflverse_pbp_data(year: int):\n",
    "    url = f'https://github.com/nflverse/nflverse-data/releases/download/pbp/play_by_play_{year}.parquet'\n",
    "    df = pl.read_parquet(url)\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb08b3dd1a3878e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T18:33:47.429074Z",
     "start_time": "2024-09-10T18:33:47.374260Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function to read parquet data from the NFL Verse repo\n",
    "def get_injuries_data(year: int):\n",
    "    url = f'https://github.com/nflverse/nflverse-data/releases/download/injuries/injuries_{year}.parquet'\n",
    "    df = pl.read_parquet(url)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5310ac021cd6cca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T18:33:50.562452Z",
     "start_time": "2024-09-10T18:33:49.417086Z"
    }
   },
   "outputs": [],
   "source": [
    "injuries_df = get_injuries_data(2024)\n",
    "injuries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b60ef50354157f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the nflverse data to a DataFrame\n",
    "roster_df = get_nflverse_roster_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced9924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "roster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a58827",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:34:43.505966Z",
     "start_time": "2024-09-09T14:34:42.342447Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "player_df = get_nflverse_player_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b15985a145290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:37:49.514856Z",
     "start_time": "2024-09-09T14:37:49.450498Z"
    }
   },
   "outputs": [],
   "source": [
    "player_df.head(200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d7db9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T18:20:43.689452Z",
     "start_time": "2024-09-09T18:20:42.321778Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "depth_charts_df = get_nflverse_depth_charts_data(2024)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5a66b46389aee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T13:32:12.400636Z",
     "start_time": "2024-09-09T13:32:12.393508Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_df = depth_charts_df.filter(\n",
    "    (pl.col(\"club_code\") == \"MIA\") & (pl.col(\"position\") == \"WR\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7d026a3f5668b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T13:32:22.467915Z",
     "start_time": "2024-09-09T13:32:22.459318Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c5db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weekly_roster_df = get_nflverse_weekly_rosters_data(2024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b7cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pbp_df = get_nflverse_pbp_data(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c78069",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_roster_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120b6617",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T18:21:03.687912Z",
     "start_time": "2024-09-09T18:21:03.284361Z"
    }
   },
   "outputs": [],
   "source": [
    "store_to_postgres(depth_charts_df, \"raw\", \"nflverse__depth_charts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a719ff7eb92277",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_headers, sorted_headers_list = get_headers(roster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c942c74aec241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp_df.sample(20, seed = 23).write_clipboard(separator=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94a6048550ce245",
   "metadata": {},
   "source": [
    "# ESPN Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f1014de0ea0c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_espn_rankings():\n",
    "    # Get the directory of the current notebook\n",
    "    notebook_dir = Path().absolute()\n",
    "    \n",
    "    # Navigate up to the project root and then to the data directory\n",
    "    project_root = notebook_dir.parent.parent\n",
    "    data_path = project_root / 'data' / 'NFL_Rankings_Complete.csv'\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not data_path.exists():\n",
    "        raise FileNotFoundError(f\"The file {data_path} does not exist.\")\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pl.read_csv(data_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb918c26a839bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the ESPN Rankings data to a DataFrame\n",
    "espn_df = get_espn_rankings()\n",
    "espn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7665a354c6c00d",
   "metadata": {},
   "source": [
    "# Draftkings Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2406ee518255f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_draftkings_rankings():\n",
    "    # Get the directory of the current notebook\n",
    "    notebook_dir = Path().absolute()\n",
    "    \n",
    "    # Navigate up to the project root and then to the data directory\n",
    "    project_root = notebook_dir.parent.parent\n",
    "    data_path = project_root / 'data' / 'DkPreDraftRankings.csv'\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not data_path.exists():\n",
    "        raise FileNotFoundError(f\"The file {data_path} does not exist.\")\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pl.read_csv(data_path)\n",
    "    return df\n",
    "\n",
    "# Test the function\n",
    "draftkings_df = get_draftkings_rankings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3333a7c2e6b94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "draftkings_df = get_draftkings_rankings()\n",
    "draftkings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dad8c82e8f2909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for name mapping\n",
    "name_mapping = {\n",
    "    \"Hollywood Brown\": \"Marquise Brown\",\n",
    "    \"DJ Chark\": \"DJ Chark Jr.\",\n",
    "    # Add more mappings as needed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaa611d6465fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply the mapping\n",
    "def map_name(name):\n",
    "    return name_mapping.get(name, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cd7f670b5ec432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the mapping to the DraftKings dataframe\n",
    "draftkings_df = draftkings_df.with_columns(\n",
    "    pl.col('Name').map_elements(map_name).alias('Mapped Name')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cff5e90107c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "draftkings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9ba5a4cceea9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_rankings(draftkings_df: pl.DataFrame, espn_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform a left join on ESPN and DraftKings dataframes based on player name.\n",
    "    \n",
    "    Args:\n",
    "    draftkings_df (pl.DataFrame): DraftKings rankings dataframe\n",
    "    espn_df (pl.DataFrame): ESPN rankings dataframe\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    pl.DataFrame: Combined dataframe with ESPN rankings as the base\n",
    "    \"\"\"\n",
    "    # Rename columns to avoid conflicts and clarify source\n",
    "    draftkings_df = draftkings_df.rename({\n",
    "        \"ADP\": \"DraftKings_ADP\",\n",
    "        \"Position\": \"DraftKings_Position\",\n",
    "        \"Team\": \"DraftKings_Team\"\n",
    "    })\n",
    "    \n",
    "    espn_df = espn_df.rename({\n",
    "        \"Overall Rank\": \"ESPN_Rank\",\n",
    "        \"Positional Rank\": \"ESPN_Positional_Rank\",\n",
    "        \"Salary Cap Value\": \"ESPN_Salary_Cap_Value\"\n",
    "    })\n",
    "    \n",
    "\n",
    "    \n",
    "    # Perform the left join\n",
    "    combined_df = draftkings_df.join(\n",
    "        espn_df,\n",
    "        left_on=\"Mapped Name\",\n",
    "        right_on=\"Player Name\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    # Drop the duplicate \"Name\" column from DraftKings\n",
    "    # combined_df = combined_df.drop(\"Name\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Example usage:\n",
    "# espn_df = pl.read_csv(\"espn_rankings_sample.csv\")\n",
    "# draftkings_df = pl.read_csv(\"draftkings_rankings_sample.csv\")\n",
    "result = combine_rankings(draftkings_df, espn_df)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db3c5ecdfc68747",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write_csv(\"combined_rankings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67165273577db129",
   "metadata": {},
   "outputs": [],
   "source": [
    "dk_to_madden_name_mapping = {\n",
    "    \"Deebo Samuel Sr.\": \"Deebo Samuel Sr\",\n",
    "    \"Marvin Harrison Jr.\": \"Marvin Harrison Jr\",\n",
    "    \"Travis Etienne Jr.\" : \"Travis Etienne Jr\",\n",
    "    \"DJ Moore\": \"D.J. Moore\",\n",
    "    \"DK Metcalf\": \"D.K. Metcalf\",\n",
    "    \"Michael Pittman Jr.\": \"Michael Pittman Jr\",\n",
    "    \"Hollywood Brown\": \"Marquise Brown\",\n",
    "    \"Brian Thomas Jr.\": \"Brian Thomas Jr\",\n",
    "    \"Brian Robinson Jr.\": \"Brian Robinson Jr\",\n",
    "    \"Marvin Mims Jr.\": \"Marvin Mims Jr\",\n",
    "    \"Tyrone Tracy Jr.\": \"Tyrone Tracy Jr\",\n",
    "    \"DJ Chark\": \"DJ Chark Jr\",\n",
    "    \"AJ Dillon\": \"A.J. Dillon\",\n",
    "    \"Chris Rodriguez Jr.\": \"Chris Rodriguez Jr\",\n",
    "    \"Odell Beckham Jr.\": \"Odell Beckham Jr\",\n",
    "    \"Michael Penix Jr.\": \"Michael Penix Jr\",\n",
    "    \"DeMario Douglas\": \"Demario Douglas\",\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "def combine_madden_with_rankings(combined_df: pl.DataFrame, madden_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform a left join on the Combined Ranks and Madden dataframes based on player name, team, and position.\n",
    "    \n",
    "    Args:\n",
    "    combined_df (pl.DataFrame): Combined rankings dataframe\n",
    "    madden_df (pl.DataFrame): Madden ratings dataframe\n",
    "\n",
    "    Returns:\n",
    "    pl.DataFrame: Combined dataframe with Combined Rankings as the base\n",
    "    \"\"\"\n",
    "    # Apply the name mapping to the combined_df\n",
    "    combined_df = combined_df.with_columns(\n",
    "        pl.when(pl.col(\"Name\").is_in(dk_to_madden_name_mapping.keys()))\n",
    "          .then(pl.col(\"Name\").replace(dk_to_madden_name_mapping))\n",
    "          .otherwise(pl.col(\"Name\"))\n",
    "          .alias(\"Mapped_Name\")\n",
    "    )\n",
    "\n",
    "    # Rename columns to avoid conflicts and clarify source\n",
    "    combined_df = combined_df.rename({\n",
    "        \"Mapped_Name\": \"Join_Name\"\n",
    "    })\n",
    "    \n",
    "    madden_df = madden_df.rename({\n",
    "        \"fullName\": \"Join_Name\",\n",
    "    })   \n",
    "\n",
    "    # Perform the left join\n",
    "    combined_madden_df = combined_df.join(\n",
    "        madden_df,\n",
    "        on=[\"Join_Name\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    # Select only the required columns from madden_df\n",
    "    madden_df_selected = combined_madden_df.select([\n",
    "        \"ID\",\n",
    "        \"Name\",\n",
    "        \"DraftKings_Position\",\n",
    "        \"DraftKings_ADP\",\n",
    "        \"DraftKings_Team\",\n",
    "        \"ESPN_Rank\",\n",
    "        \"ESPN_Positional_Rank\",\n",
    "        \"overallRating\"\n",
    "    ])    \n",
    "    \n",
    "    return madden_df_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135fda731475b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_madden_df_t = combine_madden_with_rankings(result, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa97601fb69f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_madden_df_t.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea89b3978b0c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the Madden Dataframe for Players with the fullNameForSearch *like* Marvin Harrison\n",
    "combined_madden_df_t.filter(pl.col(\"Name\").str.contains(\"DeMario\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b584472bec8e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_madden_df_t.write_csv(\"combined_madden_rankings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c5f9e1af9c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dictionary between the 'fullName' and 'Name' columns\n",
    "dk_to_madden_name_mapping = {\n",
    "    \"Deebo Samuel Sr.\": \"Deebo Samuel Sr\",\n",
    "    \"Marvin Harrison Jr.\": \"Marvin Harrison Jr\",\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "# Create a Function to apply the mapping\n",
    "def map_name(name):\n",
    "    return name_mapping.get(name, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d01a498eeecfddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Marvin Harrison in the df Dataframe\n",
    "\n",
    "df.filter(pl.col(\"fullName\").str.contains(\"Deebo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ec87d22c228fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_madden_df_t.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6223579a250de513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add a column to the df dataframe that combines firstName and lastName Columns and place it first\n",
    "madden25_df = df.with_columns([\n",
    "    pl.col(\"firstName\") + \" \" + pl.col(\"lastName\").alias(\"fullName\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4234163c91ee62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the Madden Dataframe for Players with the fullNameForSearch *like* Marvin Harrison\n",
    "madden_df.filter(pl.col(\"fullNameForSearch\").str.contains(\"Marvin Harrison\"))\n",
    "\n",
    "\n",
    "# madden_df.filter(pl.col(\"fullNameForSearch\") == \"Marvin Harrison Jr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1cc3ba2b0a207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Union, Dict\n",
    "\n",
    "BASE_URL = \"https://drop-api.ea.com/rating/madden-nfl\"\n",
    "\n",
    "class Team(BaseModel):\n",
    "    id: int\n",
    "    label: str\n",
    "    imageUrl: str\n",
    "    isPopular: bool\n",
    "\n",
    "class PositionType(BaseModel):\n",
    "    id: str\n",
    "    name: str\n",
    "\n",
    "class Position(BaseModel):\n",
    "    id: str\n",
    "    shortLabel: str\n",
    "    label: str\n",
    "    positionType: PositionType\n",
    "\n",
    "class Archetype(BaseModel):\n",
    "    id: str\n",
    "    label: str\n",
    "\n",
    "class Iteration(BaseModel):\n",
    "    id: str\n",
    "    label: str\n",
    "\n",
    "class NumericStat(BaseModel):\n",
    "    value: float\n",
    "    diff: int\n",
    "\n",
    "class RunningStyleStat(BaseModel):\n",
    "    value: str\n",
    "    diff: int\n",
    "\n",
    "class AbilityType(BaseModel):\n",
    "    id: str\n",
    "    label: str\n",
    "    imageUrl: str\n",
    "    iconUrl: str\n",
    "\n",
    "class Ability(BaseModel):\n",
    "    id: str\n",
    "    label: str\n",
    "    description: str\n",
    "    imageUrl: str\n",
    "    type: AbilityType\n",
    "\n",
    "class PlayerRating(BaseModel):\n",
    "    id: int\n",
    "    overallRating: int\n",
    "    firstName: str\n",
    "    lastName: str\n",
    "    birthdate: str\n",
    "    height: int\n",
    "    weight: int\n",
    "    college: str\n",
    "    handedness: int\n",
    "    age: int\n",
    "    jerseyNum: int\n",
    "    yearsPro: int\n",
    "    playerAbilities: List[Ability]\n",
    "    avatarUrl: Optional[str]\n",
    "    archetype: Optional[Archetype]\n",
    "    team: Team\n",
    "    position: Position\n",
    "    iteration: Iteration\n",
    "    stats: Dict[str, Union[NumericStat, RunningStyleStat]]\n",
    "\n",
    "class RatingsResponse(BaseModel):\n",
    "    items: List[PlayerRating]\n",
    "    totalItems: int\n",
    "\n",
    "def get_madden_ratings(locale: str = \"en\") -> List[PlayerRating]:\n",
    "    url = f\"{BASE_URL}?locale={locale}\"\n",
    "    all_ratings = []\n",
    "\n",
    "    with httpx.Client() as client:\n",
    "        response = client.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        ratings_response = RatingsResponse(**data)\n",
    "        all_ratings.extend(ratings_response.items)\n",
    "\n",
    "        total_count = ratings_response.totalItems\n",
    "        while len(all_ratings) < total_count:\n",
    "            next_url = f\"{url}&limit=100&offset={len(all_ratings)}\"\n",
    "            response = client.get(next_url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            ratings_response = RatingsResponse(**data)\n",
    "            all_ratings.extend(ratings_response.items)\n",
    "\n",
    "    print(f\"Total items fetched: {len(all_ratings)}\")\n",
    "    print(f\"Expected total items: {total_count}\")\n",
    "\n",
    "    return all_ratings\n",
    "\n",
    "def create_madden_nfl_dataframe():\n",
    "    ratings = get_madden_ratings()\n",
    "    \n",
    "    # Convert Pydantic models to dictionaries\n",
    "    data = [rating.dict() for rating in ratings]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pl.DataFrame(data)\n",
    "    \n",
    "    # Add fullName column\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"firstName\") + \" \" + pl.col(\"lastName\")).alias(\"fullName\")\n",
    "    ])\n",
    "    \n",
    "    # Flatten nested structures\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"team\").struct.field(\"id\").alias(\"team_id\"),\n",
    "        pl.col(\"team\").struct.field(\"label\").alias(\"team_label\"),\n",
    "        pl.col(\"team\").struct.field(\"imageUrl\").alias(\"team_imageUrl\"),\n",
    "        pl.col(\"team\").struct.field(\"isPopular\").alias(\"team_isPopular\"),\n",
    "        pl.col(\"position\").struct.field(\"id\").alias(\"position_id\"),\n",
    "        pl.col(\"position\").struct.field(\"shortLabel\").alias(\"position_shortLabel\"),\n",
    "        pl.col(\"position\").struct.field(\"label\").alias(\"position_label\"),\n",
    "        pl.col(\"position\").struct.field(\"positionType\").struct.field(\"id\").alias(\"position_type_id\"),\n",
    "        pl.col(\"position\").struct.field(\"positionType\").struct.field(\"name\").alias(\"position_type_name\"),\n",
    "        pl.col(\"iteration\").struct.field(\"id\").alias(\"iteration_id\"),\n",
    "        pl.col(\"iteration\").struct.field(\"label\").alias(\"iteration_label\"),\n",
    "    ])\n",
    "\n",
    "    # Flatten stats\n",
    "    stat_columns = df.select(pl.col(\"stats\")).to_series().struct.fields\n",
    "    for stat in stat_columns:\n",
    "        df = df.with_columns([\n",
    "            pl.col(\"stats\").struct.field(stat).struct.field(\"value\").alias(f\"stat_{stat}\")\n",
    "        ])\n",
    "\n",
    "    # Drop original nested columns\n",
    "    df = df.drop([\"team\", \"position\", \"iteration\", \"stats\", \"playerAbilities\"])\n",
    "\n",
    "    # Convert data types\n",
    "    date_columns = [\"birthdate\"]\n",
    "    int_columns = [\"id\", \"overallRating\", \"height\", \"weight\", \"handedness\", \"age\", \"jerseyNum\", \"yearsPro\", \"team_id\"]\n",
    "    float_columns = [col for col in df.columns if col.startswith(\"stat_\") and col != \"stat_runningStyle\"]\n",
    "    bool_columns = [\"team_isPopular\"]\n",
    "\n",
    "    for col in date_columns:\n",
    "        df = df.with_columns(pl.col(col).str.to_date(\"%Y-%m-%d\").alias(col))\n",
    "\n",
    "    for col in int_columns:\n",
    "        df = df.with_columns(pl.col(col).cast(pl.Int64))\n",
    "\n",
    "    for col in float_columns:\n",
    "        df = df.with_columns(pl.col(col).cast(pl.Float64))\n",
    "\n",
    "    for col in bool_columns:\n",
    "        df = df.with_columns(pl.col(col).cast(pl.Boolean))\n",
    "\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    df = create_madden_nfl_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749c50cce8073005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Column that concatenates the 'firstName' and 'lastName' columns\n",
    "madden25_df = madden25_df.with_columns([\n",
    "    pl.col(\"firstName\") + \" \" + pl.col(\"lastName\").alias(\"fullName\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d22845bb25aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "madden25_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd99a9bcc118c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
