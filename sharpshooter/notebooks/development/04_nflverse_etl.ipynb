{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T21:27:33.008935Z",
     "start_time": "2024-09-27T21:27:14.554231Z"
    }
   },
   "source": [
    "import polars as pl\n",
    "from sqlalchemy import create_engine, Column, DateTime, String\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import inspect\n",
    "from typing import Optional, Dict, Any\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from string import Template\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# SQLAlchemy setup\n",
    "Base = declarative_base()\n",
    "\n",
    "class DataUploadLog(Base):\n",
    "    __tablename__ = 'data_upload_log'\n",
    "    id = Column(String, primary_key=True)\n",
    "    data_type = Column(String)\n",
    "    year = Column(String)\n",
    "    date_uploaded = Column(DateTime)\n",
    "\n",
    "class DBConfig(BaseModel):\n",
    "    username: str = Field(default=\"\")\n",
    "    password: str = Field(default=\"\")\n",
    "    host: str = Field(default=\"localhost\")\n",
    "    port: str = Field(default=\"5432\")\n",
    "    database: str = Field(default=\"sportsdata\")\n",
    "\n",
    "class DataSourceConfig(BaseModel):\n",
    "    base_url: str = Field(default=\"https://github.com/nflverse/nflverse-data/releases/download\")\n",
    "    url_patterns: Dict[str, str] = Field(default_factory=dict)\n",
    "\n",
    "class NFLVerseDataSource:\n",
    "    def __init__(self, config: DataSourceConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def fetch_data(self, data_type: str, year: Optional[int] = None) -> pl.DataFrame:\n",
    "        if data_type not in self.config.url_patterns:\n",
    "            raise ValueError(f\"Unsupported data type: {data_type}\")\n",
    "        \n",
    "        url_template = self.config.url_patterns[data_type]\n",
    "        template = Template(url_template)\n",
    "        \n",
    "        substitution = {\n",
    "            \"base_url\": self.config.base_url,\n",
    "            \"year\": year\n",
    "        }\n",
    "\n",
    "        url = template.safe_substitute(substitution)\n",
    "\n",
    "        try:\n",
    "            df = pl.read_parquet(url)\n",
    "            df = df.with_columns([\n",
    "                pl.lit(datetime.now()).alias(\"date_uploaded\"),\n",
    "                pl.lit(data_type).alias(\"data_type\"),\n",
    "                pl.lit(str(year) if year else \"N/A\").alias(\"year\")\n",
    "            ])\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching data for {data_type} (year: {year}): {str(e)}\")\n",
    "            return None\n",
    "\n",
    "class PostgresDataStorage:\n",
    "    def __init__(self, config: DBConfig):\n",
    "        self.config = config\n",
    "        self.engine = create_engine(f\"postgresql://{config.username}:{config.password}@{config.host}:{config.port}/{config.database}\")\n",
    "        Base.metadata.create_all(self.engine)\n",
    "        self.Session = sessionmaker(bind=self.engine)\n",
    "\n",
    "    def store_data(self, df: pl.DataFrame, schema: str, table_name: str, if_exists: str = \"append\"):\n",
    "        \"\"\"\n",
    "        Store data into PostgreSQL table.\n",
    "\n",
    "        :param df: DataFrame to store.\n",
    "        :param schema: Schema name.\n",
    "        :param table_name: Table name.\n",
    "        :param if_exists: Behavior when table exists ('append' or 'replace').\n",
    "        \"\"\"\n",
    "        if df is None or df.is_empty():\n",
    "            logger.warning(f\"No data to store for {table_name}\")\n",
    "            return\n",
    "\n",
    "        session = self.Session()\n",
    "        try:\n",
    "            df.to_pandas().to_sql(table_name, self.engine, schema=schema, if_exists=if_exists, index=False)\n",
    "            if if_exists == \"replace\":\n",
    "                logger.info(f\"Data for '{schema}.{table_name}' has been replaced.\")\n",
    "            else:\n",
    "                logger.info(f\"Data successfully stored in {schema}.{table_name}\")\n",
    "            if if_exists == \"append\":\n",
    "                self._log_upload(session, table_name)\n",
    "            session.commit()\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            logger.error(f\"Error storing data to PostgreSQL: {str(e)}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    def _log_upload(self, session, table_name):\n",
    "        log_entry = DataUploadLog(\n",
    "            id=f\"{table_name}_{datetime.now().strftime('%Y%m%d%H%M%S')}\",\n",
    "            data_type=table_name,\n",
    "            year=str(datetime.now().year),\n",
    "            date_uploaded=datetime.now()\n",
    "        )\n",
    "        session.add(log_entry)\n",
    "\n",
    "    def table_exists(self, schema: str, table_name: str) -> bool:\n",
    "        \"\"\"\n",
    "        Check if a table exists in the specified schema.\n",
    "\n",
    "        :param schema: The schema name.\n",
    "        :param table_name: The table name.\n",
    "        :return: True if the table exists, False otherwise.\n",
    "        \"\"\"\n",
    "        inspector = inspect(self.engine)\n",
    "        exists = inspector.has_table(table_name, schema=schema)\n",
    "        logger.info(f\"Table '{schema}.{table_name}' exists: {exists}\")\n",
    "        return exists\n",
    "\n",
    "    def is_data_uploaded(self, table_name: str) -> bool:\n",
    "        \"\"\"\n",
    "        Check if data for the given table has already been uploaded.\n",
    "\n",
    "        :param table_name: The name of the table.\n",
    "        :return: True if data is already uploaded, False otherwise.\n",
    "        \"\"\"\n",
    "        session = self.Session()\n",
    "        try:\n",
    "            exists = session.query(DataUploadLog).filter_by(data_type=table_name).first() is not None\n",
    "            logger.info(f\"Data for table '{table_name}' already uploaded: {exists}\")\n",
    "            return exists\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error checking upload log for {table_name}: {str(e)}\")\n",
    "            return False\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "class NFLDataManager:\n",
    "    def __init__(self, data_source: NFLVerseDataSource, data_storage: PostgresDataStorage):\n",
    "        self.data_source = data_source\n",
    "        self.data_storage = data_storage\n",
    "        self.current_year = datetime.now().year\n",
    "\n",
    "    def fetch_and_store_data(self, data_type: str, year: Optional[int], schema: str, table_name: str):\n",
    "        \"\"\"\n",
    "        Fetch data from the source and store it into PostgreSQL.\n",
    "\n",
    "        :param data_type: Type of data to fetch.\n",
    "        :param year: Year of the data.\n",
    "        :param schema: Schema name in PostgreSQL.\n",
    "        :param table_name: Table name in PostgreSQL.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if year is not None:\n",
    "                if year < self.current_year:\n",
    "                    # For past seasons, skip if data already exists\n",
    "                    if self.data_storage.is_data_uploaded(table_name):\n",
    "                        logger.info(f\"Data for table '{table_name}' (year: {year}) already exists. Skipping.\")\n",
    "                        return\n",
    "                elif year == self.current_year:\n",
    "                    # For current season, replace existing data\n",
    "                    if self.data_storage.table_exists(schema, table_name):\n",
    "                        logger.info(f\"Table '{schema}.{table_name}' exists for current year. Replacing existing data.\")\n",
    "                        if_exists = \"replace\"\n",
    "                    else:\n",
    "                        if_exists = \"append\"\n",
    "                else:\n",
    "                    logger.warning(f\"Year {year} is in the future. Skipping data ingestion for '{table_name}'.\")\n",
    "                    return\n",
    "            else:\n",
    "                # Handle non-year-specific data (e.g., players)\n",
    "                if self.data_storage.is_data_uploaded(table_name):\n",
    "                    logger.info(f\"Data for table '{table_name}' has already been uploaded. Skipping.\")\n",
    "                    return\n",
    "                if_exists = \"append\"\n",
    "\n",
    "            if year == self.current_year and self.data_storage.table_exists(schema, table_name):\n",
    "                if_exists = \"replace\"\n",
    "            else:\n",
    "                if_exists = \"append\"\n",
    "\n",
    "            df = self.data_source.fetch_data(data_type, year)\n",
    "            if df is not None:\n",
    "                self.data_storage.store_data(df, schema, table_name, if_exists=if_exists)\n",
    "            else:\n",
    "                logger.warning(f\"No data fetched for {data_type} (year: {year})\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {data_type} data: {str(e)}\")\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    db_config = DBConfig(\n",
    "        username=os.getenv(\"DB_USERNAME\", \"\"),\n",
    "        password=os.getenv(\"DB_PASSWORD\", \"\"),\n",
    "        host=os.getenv(\"DB_HOST\", \"localhost\"),\n",
    "        port=os.getenv(\"DB_PORT\", \"5432\"),\n",
    "        database=os.getenv(\"DB_NAME\", \"sportsdata\")\n",
    "    )\n",
    "\n",
    "    data_source_config = DataSourceConfig(\n",
    "        base_url=\"https://github.com/nflverse/nflverse-data/releases/download\",\n",
    "        url_patterns={\n",
    "            \"weekly_rosters\": \"${base_url}/weekly_rosters/roster_weekly_${year}.parquet\",\n",
    "            \"depth_charts\": \"${base_url}/depth_charts/depth_charts_${year}.parquet\",\n",
    "            \"pbp\": \"${base_url}/pbp/play_by_play_${year}.parquet\",\n",
    "            \"players\": \"${base_url}/players/players.parquet\",\n",
    "            \"injuries\": \"${base_url}/injuries/injuries_${year}.parquet\",\n",
    "            \"player_stats\": \"${base_url}/player_stats/player_stats_${year}.parquet\",\n",
    "            \"rosters\": \"${base_url}/rosters/roster_${year}.parquet\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    data_source = NFLVerseDataSource(data_source_config)\n",
    "    data_storage = PostgresDataStorage(db_config)\n",
    "    nfl_data_manager = NFLDataManager(data_source, data_storage)\n",
    "\n",
    "    current_year = datetime.now().year\n",
    "    previous_year = current_year - 1\n",
    "\n",
    "    # Try current year first, if not available, use previous year\n",
    "    for year in [current_year, previous_year]:\n",
    "        nfl_data_manager.fetch_and_store_data(\"weekly_rosters\", year, \"raw\", f\"nflverse__weekly_rosters_{year}\")\n",
    "        nfl_data_manager.fetch_and_store_data(\"depth_charts\", year, \"raw\", f\"nflverse__depth_charts_{year}\")\n",
    "        nfl_data_manager.fetch_and_store_data(\"pbp\", year, \"raw\", f\"nflverse__pbp_{year}\")\n",
    "        nfl_data_manager.fetch_and_store_data(\"injuries\", year, \"raw\", f\"nflverse__injuries_{year}\")\n",
    "        nfl_data_manager.fetch_and_store_data(\"player_stats\", year, \"raw\", f\"nflverse__player_stats_{year}\")\n",
    "        nfl_data_manager.fetch_and_store_data(\"rosters\", year, \"raw\", f\"nflverse__rosters_{year}\")\n",
    "\n",
    "\n",
    "    # Fetch players data (not year-specific)\n",
    "    nfl_data_manager.fetch_and_store_data(\"players\", None, \"raw\", \"nflverse__players\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 17:27:14,746 - INFO - Table 'raw.nflverse__weekly_rosters_2024' exists: True\n",
      "2024-09-27 17:27:14,746 - INFO - Table 'raw.nflverse__weekly_rosters_2024' exists for current year. Replacing existing data.\n",
      "2024-09-27 17:27:14,747 - INFO - Table 'raw.nflverse__weekly_rosters_2024' exists: True\n",
      "2024-09-27 17:27:17,102 - INFO - Data for 'raw.nflverse__weekly_rosters_2024' has been replaced.\n",
      "2024-09-27 17:27:17,113 - INFO - Table 'raw.nflverse__depth_charts_2024' exists: True\n",
      "2024-09-27 17:27:17,113 - INFO - Table 'raw.nflverse__depth_charts_2024' exists for current year. Replacing existing data.\n",
      "2024-09-27 17:27:17,114 - INFO - Table 'raw.nflverse__depth_charts_2024' exists: True\n",
      "2024-09-27 17:27:18,618 - INFO - Data for 'raw.nflverse__depth_charts_2024' has been replaced.\n",
      "2024-09-27 17:27:18,624 - INFO - Table 'raw.nflverse__pbp_2024' exists: True\n",
      "2024-09-27 17:27:18,624 - INFO - Table 'raw.nflverse__pbp_2024' exists for current year. Replacing existing data.\n",
      "2024-09-27 17:27:18,625 - INFO - Table 'raw.nflverse__pbp_2024' exists: True\n",
      "2024-09-27 17:27:29,449 - INFO - Data for 'raw.nflverse__pbp_2024' has been replaced.\n",
      "2024-09-27 17:27:29,465 - INFO - Table 'raw.nflverse__injuries_2024' exists: True\n",
      "2024-09-27 17:27:29,466 - INFO - Table 'raw.nflverse__injuries_2024' exists for current year. Replacing existing data.\n",
      "2024-09-27 17:27:29,467 - INFO - Table 'raw.nflverse__injuries_2024' exists: True\n",
      "2024-09-27 17:27:30,548 - INFO - Data for 'raw.nflverse__injuries_2024' has been replaced.\n",
      "2024-09-27 17:27:30,550 - INFO - Table 'raw.nflverse__player_stats_2024' exists: True\n",
      "2024-09-27 17:27:30,550 - INFO - Table 'raw.nflverse__player_stats_2024' exists for current year. Replacing existing data.\n",
      "2024-09-27 17:27:30,551 - INFO - Table 'raw.nflverse__player_stats_2024' exists: True\n",
      "2024-09-27 17:27:31,639 - INFO - Data for 'raw.nflverse__player_stats_2024' has been replaced.\n",
      "2024-09-27 17:27:31,641 - INFO - Table 'raw.nflverse__rosters_2024' exists: True\n",
      "2024-09-27 17:27:31,642 - INFO - Table 'raw.nflverse__rosters_2024' exists for current year. Replacing existing data.\n",
      "2024-09-27 17:27:31,643 - INFO - Table 'raw.nflverse__rosters_2024' exists: True\n",
      "2024-09-27 17:27:32,985 - INFO - Data for 'raw.nflverse__rosters_2024' has been replaced.\n",
      "2024-09-27 17:27:32,993 - INFO - Data for table 'nflverse__weekly_rosters_2023' already uploaded: True\n",
      "2024-09-27 17:27:32,994 - INFO - Data for table 'nflverse__weekly_rosters_2023' (year: 2023) already exists. Skipping.\n",
      "2024-09-27 17:27:32,995 - INFO - Data for table 'nflverse__depth_charts_2023' already uploaded: True\n",
      "2024-09-27 17:27:32,996 - INFO - Data for table 'nflverse__depth_charts_2023' (year: 2023) already exists. Skipping.\n",
      "2024-09-27 17:27:32,997 - INFO - Data for table 'nflverse__pbp_2023' already uploaded: True\n",
      "2024-09-27 17:27:32,997 - INFO - Data for table 'nflverse__pbp_2023' (year: 2023) already exists. Skipping.\n",
      "2024-09-27 17:27:32,998 - INFO - Data for table 'nflverse__injuries_2023' already uploaded: True\n",
      "2024-09-27 17:27:32,998 - INFO - Data for table 'nflverse__injuries_2023' (year: 2023) already exists. Skipping.\n",
      "2024-09-27 17:27:32,999 - INFO - Data for table 'nflverse__player_stats_2023' already uploaded: True\n",
      "2024-09-27 17:27:32,999 - INFO - Data for table 'nflverse__player_stats_2023' (year: 2023) already exists. Skipping.\n",
      "2024-09-27 17:27:33,000 - INFO - Data for table 'nflverse__rosters_2023' already uploaded: True\n",
      "2024-09-27 17:27:33,001 - INFO - Data for table 'nflverse__rosters_2023' (year: 2023) already exists. Skipping.\n",
      "2024-09-27 17:27:33,006 - INFO - Data for table 'nflverse__players' already uploaded: True\n",
      "2024-09-27 17:27:33,006 - INFO - Data for table 'nflverse__players' has already been uploaded. Skipping.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1673"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
